<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>Zelvora Handfree Tutor</title>

<style>
*{margin:0;padding:0;box-sizing:border-box}
body{
  font-family:system-ui,-apple-system,BlinkMacSystemFont;
  background:linear-gradient(135deg,#0f1729,#1a2a4a);
  color:#e5e7eb;
  min-height:100vh;
}
header{
  background:rgba(15,23,41,.95);
  padding:18px;
  text-align:center;
  border-bottom:1px solid rgba(31,122,255,.25);
}
.logo{
  font-size:26px;
  font-weight:700;
  background:linear-gradient(135deg,#1f7aff,#764ba2);
  -webkit-background-clip:text;
  -webkit-text-fill-color:transparent;
}
.status{
  margin-top:6px;
  font-weight:600;
}
.container{
  max-width:900px;
  margin:auto;
  padding:20px;
  display:flex;
  flex-direction:column;
  gap:18px;
}
.card{
  background:rgba(31,122,255,.08);
  border:1px solid rgba(31,122,255,.25);
  border-radius:14px;
  padding:20px;
}
.center{text-align:center}
.mic{
  font-size:70px;
  margin-bottom:12px;
}
.detected{
  background:#0b122e;
  padding:14px;
  border-radius:10px;
  margin-top:10px;
  min-height:48px;
}
.note{
  font-size:14px;
  color:#94a3b8;
}
.controls{
  display:flex;
  justify-content:center;
  gap:12px;
  flex-wrap:wrap;
}
button{
  padding:12px 22px;
  border:none;
  border-radius:10px;
  font-weight:600;
  cursor:pointer;
}
.start{background:#1f7aff;color:white}
.stop{background:#ff6b6b;color:black}
.reset{background:#334155;color:white}
.success{color:#4ade80}
.error{color:#ff6b6b}
</style>
</head>

<body>

<header>
  <div class="logo">üéôÔ∏è Zelvora Handfree Tutor</div>
  <div class="status" id="statusText">Ready</div>
</header>

<div class="container">

  <div class="card center">
    <div class="mic" id="micIcon">üéß</div>
    <div>Click <b>Start Listening</b> and speak</div>
    <div class="detected" id="detectedText">Waiting for speech‚Ä¶</div>
  </div>

  <div class="card">
    <b>üîç AI Feedback</b>
    <div id="feedback" class="note">Feedback will appear here‚Ä¶</div>
  </div>

  <div class="card">
    <b>üìù Transcript</b>
    <div id="transcript" class="note">Your spoken text will appear here‚Ä¶</div>
  </div>

  <div class="controls">
    <button class="start" onclick="startListening()">üé§ Start Listening</button>
    <button class="stop" onclick="stopListening()">‚èπ Stop</button>
    <button class="reset" onclick="resetSession()">üîÑ Reset</button>
  </div>

</div>

<script>
const API_ENDPOINT = "https://zelvora-ai.zelvora-global.workers.dev";

const SpeechRecognition =
  window.SpeechRecognition || window.webkitSpeechRecognition;

let recognition;
let listening = false;

function initSpeech() {
  if (!SpeechRecognition) {
    statusText.textContent = "Speech Recognition not supported";
    return;
  }

  recognition = new SpeechRecognition();
  recognition.continuous = true;
  recognition.interimResults = true;
  recognition.lang = "en-US";

  recognition.onstart = () => {
    statusText.textContent = "üéôÔ∏è Listening‚Ä¶";
    micIcon.textContent = "üé§";
  };

  recognition.onend = () => {
    listening = false;
    statusText.textContent = "Ready";
    micIcon.textContent = "üéß";
  };

  recognition.onerror = (e) => {
    let msg = e.error;
    if (e.error === "not-allowed") {
      msg = "‚ùå Microphone blocked. Allow mic in browser settings.";
    }
    statusText.textContent = msg;
  };

  recognition.onresult = async (event) => {
    let interim = "";
    let finalText = "";

    for (let i = event.resultIndex; i < event.results.length; i++) {
      const t = event.results[i][0].transcript;
      event.results[i].isFinal ? finalText += t + " " : interim += t;
    }

    if (interim) {
      detectedText.textContent = interim + "...";
    }

    if (finalText) {
      const clean = finalText.trim();
      detectedText.textContent = clean;
      transcript.innerHTML += `<div>‚Ä¢ ${clean}</div>`;
      feedback.textContent = "Analyzing‚Ä¶";

      const aiReply = await sendToAI(clean);
      feedback.innerHTML = `<div class="success">${aiReply}</div>`;
    }
  };
}

async function sendToAI(text) {
  try {
    const res = await fetch(API_ENDPOINT, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        prompt: `Analyze and improve this spoken English:\n"${text}"`,
        mode: "general"
      })
    });
    const data = await res.json();
    return data.reply || "No AI response.";
  } catch {
    return "‚ùå Unable to reach Zelvora AI.";
  }
}

function startListening() {
  if (listening) return;
  listening = true;
  setTimeout(() => {
    try { recognition.start(); } catch {}
  }, 300);
}

function stopListening() {
  recognition && recognition.stop();
}

function resetSession() {
  detectedText.textContent = "Waiting for speech‚Ä¶";
  feedback.textContent = "Feedback will appear here‚Ä¶";
  transcript.textContent = "Your spoken text will appear here‚Ä¶";
}

document.addEventListener("DOMContentLoaded", initSpeech);
</script>

</body>
</html>
