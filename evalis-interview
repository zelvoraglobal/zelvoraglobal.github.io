<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Evalis AI – Live Interview</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>

<style>
:root { --primary:#6366f1; --bg:#020617; }
body {
  margin:0;
  background:var(--bg);
  color:white;
  font-family:system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
  display:flex;
  align-items:center;
  justify-content:center;
  min-height:100vh;
}
.card {
  width:90%;
  max-width:440px;
  background:rgba(255,255,255,.05);
  border-radius:22px;
  padding:28px;
  text-align:center;
  border:1px solid rgba(255,255,255,.12);
  box-shadow: 0 4px 30px rgba(0, 0, 0, 0.1);
  backdrop-filter: blur(5px);
}
button {
  background:var(--primary);
  color:white;
  border:none;
  padding:14px;
  border-radius:14px;
  width:100%;
  font-size:16px;
  font-weight:700;
  margin-top:10px;
  cursor: pointer;
  transition: opacity 0.2s;
}
button:disabled { opacity:.35; cursor: not-allowed; }
button:active { opacity: 0.8; }
#log {
  margin-top:20px;
  max-height:220px;
  overflow-y:auto;
  text-align:left;
  font-size:14px;
  line-height: 1.5;
  padding-right: 5px;
}
/* Custom Scrollbar for log */
#log::-webkit-scrollbar { width: 6px; }
#log::-webkit-scrollbar-thumb { background: rgba(255,255,255,0.2); border-radius: 3px; }
small { color:#94a3b8; display: block; margin-bottom: 15px; }
.msg { margin-bottom: 8px; }
.msg b { color: var(--primary); }
</style>
</head>

<body>

<div class="card">
  <h2 id="timer">15:00</h2>
  <p id="status">Upload resume to begin</p>

  <input type="file" id="cvInput" accept="application/pdf">
  <small id="uploadStatus"></small>

  <button id="startBtn" disabled>Start Interview</button>
  <button id="endBtn" style="display:none;background:#ef4444">End Interview</button>

  <div id="log"></div>
</div>

<script>
/* ======================================================
   CONFIG & SETUP
====================================================== */
const API = "https://evalis-ai.simpaticohrconsultancy.workers.dev";
pdfjsLib.GlobalWorkerOptions.workerSrc = "https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js";

/* ======================================================
   STATE MANAGEMENT
====================================================== */
let cvText = "";
let history = [];
let interviewActive = false;
let recognition = null;
let isAISpeaking = false;

/* ======================================================
   UI HELPERS
====================================================== */
function addMsg(who, text) {
  const div = document.createElement("div");
  div.className = "msg";
  // Color code speakers
  const color = who === "AI" ? "#a5b4fc" : "#86efac";
  div.innerHTML = `<b style="color:${color}">${who}:</b> ${text}`;
  document.getElementById("log").prepend(div);
}

/* ======================================================
   TEXT TO SPEECH (FIXED FOR ANDROID)
====================================================== */
function speak(text) {
  // 1. Android Native Bridge (Preferred)
  // Checks if 'Android' object exists and has the 'speak' method
  if (typeof Android !== "undefined" && Android.speak) {
    console.log("Speaking via Android Native Interface");
    Android.speak(text);
    return;
  }

  // 2. Browser Fallback (Web Speech API)
  if (!window.speechSynthesis) {
    console.warn("No TTS support found");
    return;
  }

  // Cancel any currently playing audio to avoid overlap
  speechSynthesis.cancel();

  const u = new SpeechSynthesisUtterance(text);
  u.lang = "en-US";
  u.rate = 1.0; // Normal speed

  // Stop listening while AI speaks to avoid AI hearing itself
  u.onstart = () => {
    isAISpeaking = true;
    if (recognition) recognition.stop();
  };

  // Resume listening after AI finishes
  u.onend = () => {
    isAISpeaking = false;
    if (interviewActive && recognition) {
        try { recognition.start(); } catch(e) {}
    }
  };

  speechSynthesis.speak(u);
}

/* ======================================================
   SPEECH RECOGNITION (BROWSER ONLY)
   Note: Android App usually injects text via receiveVoskText
====================================================== */
function initRecognition() {
  // If we are in the Android App (native), we skip browser recognition
  if (typeof Android !== "undefined") return;

  const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
  if (!SR) return;

  recognition = new SR();
  recognition.lang = "en-US";
  recognition.continuous = false; // We restart manually for better control
  recognition.interimResults = false;

  recognition.onresult = e => {
    if (isAISpeaking) return;
    const text = e.results[0][0].transcript.trim();
    if (text) sendUserText(text);
  };

  recognition.onend = () => {
    // Auto-restart if interview is active and AI isn't speaking
    if (interviewActive && !isAISpeaking) {
        try { recognition.start(); } catch(e) {}
    }
  };
}

/* ======================================================
   FILE UPLOAD & PARSING
====================================================== */
document.getElementById("cvInput").onchange = async e => {
  const file = e.target.files[0];
  const status = document.getElementById("uploadStatus");
  const btn = document.getElementById("startBtn");

  if (!file) return;
  
  status.textContent = "Reading resume…";
  btn.disabled = true;

  try {
    const buffer = await file.arrayBuffer();
    const pdf = await pdfjsLib.getDocument({
      data: buffer,
      disableWorker: true
    }).promise;

    let text = "";
    for (let i = 1; i <= pdf.numPages; i++) {
      const page = await pdf.getPage(i);
      const c = await page.getTextContent();
      text += c.items.map(it => it.str).join(" ") + " ";
    }

    // Basic validation
    if (text.trim().length < 50) throw new Error("Resume too short or unreadable");
    
    cvText = text;
    btn.disabled = false;
    status.textContent = "Resume ready ✓";

  } catch (err) {
    console.error(err);
    status.textContent = "Error reading PDF. Try a different file.";
  }
};

/* ======================================================
   START INTERVIEW LOGIC
====================================================== */
document.getElementById("startBtn").onclick = async () => {
  const btn = document.getElementById("startBtn");
  
  // --- CRITICAL FIX: UNLOCK AUDIO ---
  // Mobile browsers block audio unless triggered by a click.
  // We play a silent utterance immediately to "unlock" the audio engine.
  if (window.speechSynthesis) {
      const dummy = new SpeechSynthesisUtterance("");
      speechSynthesis.speak(dummy);
  }
  // ----------------------------------

  interviewActive = true;
  btn.style.display = "none";
  document.getElementById("endBtn").style.display = "block";
  document.getElementById("status").textContent = "Connecting to AI…";

  initRecognition();

  const fd = new FormData();
  fd.append("mode", "start");
  fd.append("cvText", cvText);

  try {
      const r = await fetch(API, { method: "POST", body: fd });
      if (!r.ok) throw new Error("Server error");
      
      const d = await r.json();

      history = d.history || [];
      addMsg("AI", d.reply);
      speak(d.reply);
      
      document.getElementById("status").textContent = "Listening…";
      if (recognition) recognition.start();
      
  } catch (err) {
      alert("Failed to start interview: " + err.message);
      interviewActive = false;
      btn.style.display = "block";
      document.getElementById("endBtn").style.display = "none";
      document.getElementById("status").textContent = "Resume ready ✓";
  }
};

/* ======================================================
   ANDROID/VOSK INTERFACE
   (Called by Android Java code)
====================================================== */
window.receiveVoskText = text => {
  if (!interviewActive || !text) return;
  sendUserText(text);
};

/* ======================================================
   SEND MESSAGE TO AI
====================================================== */
async function sendUserText(text) {
  addMsg("You", text);
  document.getElementById("status").textContent = "AI is thinking…";

  const fd = new FormData();
  fd.append("mode", "interview");
  fd.append("text", text);
  fd.append("history", JSON.stringify(history));
  fd.append("cvText", cvText);

  try {
      const r = await fetch(API, { method: "POST", body: fd });
      const d = await r.json();

      history = d.history || history;
      addMsg("AI", d.reply);
      speak(d.reply);
      document.getElementById("status").textContent = "Listening…";
      
  } catch (err) {
      addMsg("System", "Error connecting to AI.");
      document.getElementById("status").textContent = "Connection Error";
  }
}

/* ======================================================
   END INTERVIEW
====================================================== */
document.getElementById("endBtn").onclick = async () => {
  interviewActive = false;
  if (recognition) recognition.stop();
  if (window.speechSynthesis) speechSynthesis.cancel();

  document.getElementById("status").textContent = "Generating feedback…";
  
  const fd = new FormData();
  fd.append("mode", "score");
  fd.append("history", JSON.stringify(history));

  try {
      const r = await fetch(API, { method: "POST", body: fd });
      const d = await r.json();

      document.body.innerHTML = `
        <div class="card">
          <h2>Interview Complete</h2>
          <div style="text-align:left;max-height:60vh;overflow:auto;white-space:pre-wrap;font-size:14px;background:rgba(0,0,0,0.2);padding:15px;border-radius:10px;">${d.reply}</div>
          <button onclick="location.reload()">New Interview</button>
        </div>`;
  } catch (err) {
      alert("Error generating feedback.");
      location.reload();
  }
};
</script>

</body>
</html>
